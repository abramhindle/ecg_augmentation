{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "aa77d28b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from helper_code import *\n",
    "import numpy as np, os, sys, joblib\n",
    "import ecg_plot\n",
    "import pandas as pd\n",
    "from glob import glob\n",
    "import os\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tsai.all import *\n",
    "import torch\n",
    "import optuna\n",
    "from optuna.integration import FastAIPruningCallback\n",
    "import transformation_funcs as custom_tfms\n",
    "torch.cuda.set_device(1) \n",
    "\n",
    "\n",
    "def snomedConvert(code,snomed=True):\n",
    "    codes =  pd.read_csv(\"data/codes.csv\",sep=\";\")[[\"Dx\",\"SNOMED CT Code\"]]\n",
    "    if snomed:\n",
    "        df.columns = [codes[codes[\"SNOMED CT Code\"] == int(x)].iloc[0][\"Dx\"] for x in df.columns]\n",
    "        return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "379de773",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv(\"data/WFDB_CPSC2018.csv\")\n",
    "codes =  pd.read_csv(\"data/codes.csv\",sep=\";\")\n",
    "# df.columns = [codes[codes[\"SNOMED CT Code\"] == x].iloc[0][\"Dx\"] for x in df.columns]\n",
    "np.sum(codes[\"SNOMED CT Code\"] == int(df.columns[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "25c1119b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ True, False, False, ..., False, False, False])"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X = np.load('./data/big_numpy_datasets/WFDB_CPSC2018.npy', mmap_mode='c')\n",
    "df = pd.read_csv(\"data/WFDB_CPSC2018.csv\").drop(columns=[\"headers\",\"leads\"])\n",
    "\n",
    "y = snomedConvert(df)\n",
    "y = y[y.columns[0]].to_numpy()\n",
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8bbf277e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1152x36 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "((#5503) [6512,6719,568,3007,5266,2620,287,3001,6680,3730...],\n",
       " (#687) [5943,4366,1156,1709,4109,6237,3598,3607,5000,1037...],\n",
       " (#687) [2626,5678,5053,2717,3363,963,5856,5471,1253,148...])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "splits = get_splits(y, valid_size=.1,test_size=0.1, stratify=True, random_state=23, shuffle=True)\n",
    "splits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ce744730",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Counts by label: {'right bundle branch block': 1857, 'sinus rhythm': 918, 'atrial fibrillation': 1221, 'ventricular ectopics': 700, 'st depression': 869, 'left bundle branch block': 236, 'st elevation': 220, '1st degree av block': 722, 'premature atrial contraction': 616}\n"
     ]
    }
   ],
   "source": [
    "df = pd.read_csv(\"data/WFDB_CPSC2018.csv\").drop(columns=[\"headers\",\"leads\"])\n",
    "y = snomedConvert(df)\n",
    "y_multi = []\n",
    "for i,row in y.iterrows():\n",
    "    sample_labels = []\n",
    "    for i,r in enumerate(row):\n",
    "        if r == True:\n",
    "            sample_labels.append(y.columns[i])\n",
    "        \n",
    "    y_multi.append(list(tuple(sample_labels)))\n",
    "label_counts = collections.Counter([a for r in y_multi for a in r])\n",
    "print('Counts by label:', dict(label_counts))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2fa86512",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-03-12 14:42:47,422]\u001b[0m Using an existing study with name 'inception_study3' instead of creating a new one.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "<style>\n",
       "    /* Turns off some styling */\n",
       "    progress {\n",
       "        /* gets rid of default border in Firefox and Opera. */\n",
       "        border: none;\n",
       "        /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
       "        background-size: auto;\n",
       "    }\n",
       "    .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n",
       "        background: #F44336;\n",
       "    }\n",
       "</style>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      <progress value='33' class='' max='100' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      33.00% [33/100 14:34<29:36]\n",
       "    </div>\n",
       "    \n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>epoch</th>\n",
       "      <th>train_loss</th>\n",
       "      <th>valid_loss</th>\n",
       "      <th>accuracy_multi</th>\n",
       "      <th>balanced_accuracy_multi</th>\n",
       "      <th>precision_multi</th>\n",
       "      <th>recall_multi</th>\n",
       "      <th>specificity_multi</th>\n",
       "      <th>F1_multi</th>\n",
       "      <th>time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>0.585919</td>\n",
       "      <td>0.524662</td>\n",
       "      <td>0.898431</td>\n",
       "      <td>0.611585</td>\n",
       "      <td>0.728057</td>\n",
       "      <td>0.235103</td>\n",
       "      <td>0.988067</td>\n",
       "      <td>0.355176</td>\n",
       "      <td>00:26</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.471091</td>\n",
       "      <td>0.413056</td>\n",
       "      <td>0.906680</td>\n",
       "      <td>0.626262</td>\n",
       "      <td>0.859211</td>\n",
       "      <td>0.258215</td>\n",
       "      <td>0.994308</td>\n",
       "      <td>0.397006</td>\n",
       "      <td>00:25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.366726</td>\n",
       "      <td>0.312084</td>\n",
       "      <td>0.914928</td>\n",
       "      <td>0.658547</td>\n",
       "      <td>0.899834</td>\n",
       "      <td>0.322051</td>\n",
       "      <td>0.995044</td>\n",
       "      <td>0.473741</td>\n",
       "      <td>00:25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.293095</td>\n",
       "      <td>0.256646</td>\n",
       "      <td>0.918971</td>\n",
       "      <td>0.676154</td>\n",
       "      <td>0.903944</td>\n",
       "      <td>0.357449</td>\n",
       "      <td>0.994860</td>\n",
       "      <td>0.511479</td>\n",
       "      <td>00:25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.246230</td>\n",
       "      <td>0.224942</td>\n",
       "      <td>0.921074</td>\n",
       "      <td>0.694333</td>\n",
       "      <td>0.870632</td>\n",
       "      <td>0.396744</td>\n",
       "      <td>0.991921</td>\n",
       "      <td>0.544208</td>\n",
       "      <td>00:25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.214679</td>\n",
       "      <td>0.207465</td>\n",
       "      <td>0.923823</td>\n",
       "      <td>0.708808</td>\n",
       "      <td>0.865664</td>\n",
       "      <td>0.426612</td>\n",
       "      <td>0.991004</td>\n",
       "      <td>0.570993</td>\n",
       "      <td>00:25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>0.190519</td>\n",
       "      <td>0.188553</td>\n",
       "      <td>0.936115</td>\n",
       "      <td>0.768083</td>\n",
       "      <td>0.867555</td>\n",
       "      <td>0.547549</td>\n",
       "      <td>0.988617</td>\n",
       "      <td>0.670701</td>\n",
       "      <td>00:25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>0.174010</td>\n",
       "      <td>0.176877</td>\n",
       "      <td>0.939673</td>\n",
       "      <td>0.785379</td>\n",
       "      <td>0.868285</td>\n",
       "      <td>0.582873</td>\n",
       "      <td>0.987884</td>\n",
       "      <td>0.696995</td>\n",
       "      <td>00:25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>0.166965</td>\n",
       "      <td>0.170583</td>\n",
       "      <td>0.938218</td>\n",
       "      <td>0.786314</td>\n",
       "      <td>0.848022</td>\n",
       "      <td>0.586948</td>\n",
       "      <td>0.985680</td>\n",
       "      <td>0.693016</td>\n",
       "      <td>00:26</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>0.160901</td>\n",
       "      <td>0.185133</td>\n",
       "      <td>0.934983</td>\n",
       "      <td>0.787358</td>\n",
       "      <td>0.809392</td>\n",
       "      <td>0.593624</td>\n",
       "      <td>0.981091</td>\n",
       "      <td>0.684476</td>\n",
       "      <td>00:26</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>0.155528</td>\n",
       "      <td>0.168321</td>\n",
       "      <td>0.938541</td>\n",
       "      <td>0.802319</td>\n",
       "      <td>0.815909</td>\n",
       "      <td>0.623549</td>\n",
       "      <td>0.981090</td>\n",
       "      <td>0.706112</td>\n",
       "      <td>00:26</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>11</td>\n",
       "      <td>0.153276</td>\n",
       "      <td>0.168524</td>\n",
       "      <td>0.937409</td>\n",
       "      <td>0.797609</td>\n",
       "      <td>0.815169</td>\n",
       "      <td>0.614129</td>\n",
       "      <td>0.981089</td>\n",
       "      <td>0.700240</td>\n",
       "      <td>00:26</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>12</td>\n",
       "      <td>0.152368</td>\n",
       "      <td>0.160818</td>\n",
       "      <td>0.941452</td>\n",
       "      <td>0.802856</td>\n",
       "      <td>0.846813</td>\n",
       "      <td>0.620950</td>\n",
       "      <td>0.984763</td>\n",
       "      <td>0.715971</td>\n",
       "      <td>00:26</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>13</td>\n",
       "      <td>0.149419</td>\n",
       "      <td>0.167114</td>\n",
       "      <td>0.941291</td>\n",
       "      <td>0.806300</td>\n",
       "      <td>0.837999</td>\n",
       "      <td>0.629124</td>\n",
       "      <td>0.983476</td>\n",
       "      <td>0.718197</td>\n",
       "      <td>00:26</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>14</td>\n",
       "      <td>0.145027</td>\n",
       "      <td>0.168049</td>\n",
       "      <td>0.940805</td>\n",
       "      <td>0.804806</td>\n",
       "      <td>0.837589</td>\n",
       "      <td>0.626320</td>\n",
       "      <td>0.983292</td>\n",
       "      <td>0.715972</td>\n",
       "      <td>00:26</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>15</td>\n",
       "      <td>0.144376</td>\n",
       "      <td>0.172198</td>\n",
       "      <td>0.942099</td>\n",
       "      <td>0.814979</td>\n",
       "      <td>0.829216</td>\n",
       "      <td>0.648134</td>\n",
       "      <td>0.981825</td>\n",
       "      <td>0.726785</td>\n",
       "      <td>00:26</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>16</td>\n",
       "      <td>0.142758</td>\n",
       "      <td>0.173725</td>\n",
       "      <td>0.936762</td>\n",
       "      <td>0.799584</td>\n",
       "      <td>0.804229</td>\n",
       "      <td>0.619548</td>\n",
       "      <td>0.979621</td>\n",
       "      <td>0.699722</td>\n",
       "      <td>00:26</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>17</td>\n",
       "      <td>0.142929</td>\n",
       "      <td>0.165910</td>\n",
       "      <td>0.942261</td>\n",
       "      <td>0.823253</td>\n",
       "      <td>0.814589</td>\n",
       "      <td>0.667067</td>\n",
       "      <td>0.979438</td>\n",
       "      <td>0.733026</td>\n",
       "      <td>00:26</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>18</td>\n",
       "      <td>0.139661</td>\n",
       "      <td>0.186608</td>\n",
       "      <td>0.932719</td>\n",
       "      <td>0.793779</td>\n",
       "      <td>0.775891</td>\n",
       "      <td>0.611424</td>\n",
       "      <td>0.976134</td>\n",
       "      <td>0.683355</td>\n",
       "      <td>00:26</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>19</td>\n",
       "      <td>0.134261</td>\n",
       "      <td>0.164022</td>\n",
       "      <td>0.944525</td>\n",
       "      <td>0.829300</td>\n",
       "      <td>0.824937</td>\n",
       "      <td>0.678061</td>\n",
       "      <td>0.980539</td>\n",
       "      <td>0.743898</td>\n",
       "      <td>00:26</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>20</td>\n",
       "      <td>0.135053</td>\n",
       "      <td>0.142621</td>\n",
       "      <td>0.951156</td>\n",
       "      <td>0.841239</td>\n",
       "      <td>0.867003</td>\n",
       "      <td>0.696983</td>\n",
       "      <td>0.985496</td>\n",
       "      <td>0.772205</td>\n",
       "      <td>00:26</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>21</td>\n",
       "      <td>0.134696</td>\n",
       "      <td>0.160536</td>\n",
       "      <td>0.943070</td>\n",
       "      <td>0.825464</td>\n",
       "      <td>0.817713</td>\n",
       "      <td>0.671124</td>\n",
       "      <td>0.979805</td>\n",
       "      <td>0.736736</td>\n",
       "      <td>00:26</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>22</td>\n",
       "      <td>0.130159</td>\n",
       "      <td>0.169465</td>\n",
       "      <td>0.940320</td>\n",
       "      <td>0.816275</td>\n",
       "      <td>0.808500</td>\n",
       "      <td>0.653479</td>\n",
       "      <td>0.979071</td>\n",
       "      <td>0.722602</td>\n",
       "      <td>00:26</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>23</td>\n",
       "      <td>0.127434</td>\n",
       "      <td>0.189079</td>\n",
       "      <td>0.935630</td>\n",
       "      <td>0.794795</td>\n",
       "      <td>0.801616</td>\n",
       "      <td>0.609968</td>\n",
       "      <td>0.979622</td>\n",
       "      <td>0.692507</td>\n",
       "      <td>00:26</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>24</td>\n",
       "      <td>0.127131</td>\n",
       "      <td>0.150709</td>\n",
       "      <td>0.948245</td>\n",
       "      <td>0.829043</td>\n",
       "      <td>0.862223</td>\n",
       "      <td>0.672589</td>\n",
       "      <td>0.985497</td>\n",
       "      <td>0.754859</td>\n",
       "      <td>00:26</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>25</td>\n",
       "      <td>0.123098</td>\n",
       "      <td>0.143575</td>\n",
       "      <td>0.949539</td>\n",
       "      <td>0.842068</td>\n",
       "      <td>0.849747</td>\n",
       "      <td>0.701026</td>\n",
       "      <td>0.983110</td>\n",
       "      <td>0.767528</td>\n",
       "      <td>00:26</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>26</td>\n",
       "      <td>0.121214</td>\n",
       "      <td>0.156240</td>\n",
       "      <td>0.946628</td>\n",
       "      <td>0.830463</td>\n",
       "      <td>0.842872</td>\n",
       "      <td>0.678002</td>\n",
       "      <td>0.982925</td>\n",
       "      <td>0.750902</td>\n",
       "      <td>00:26</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>27</td>\n",
       "      <td>0.118371</td>\n",
       "      <td>0.168010</td>\n",
       "      <td>0.943070</td>\n",
       "      <td>0.836061</td>\n",
       "      <td>0.799890</td>\n",
       "      <td>0.695620</td>\n",
       "      <td>0.976501</td>\n",
       "      <td>0.743483</td>\n",
       "      <td>00:26</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>28</td>\n",
       "      <td>0.114020</td>\n",
       "      <td>0.149293</td>\n",
       "      <td>0.946628</td>\n",
       "      <td>0.835159</td>\n",
       "      <td>0.834388</td>\n",
       "      <td>0.688862</td>\n",
       "      <td>0.981456</td>\n",
       "      <td>0.754466</td>\n",
       "      <td>00:26</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>29</td>\n",
       "      <td>0.115377</td>\n",
       "      <td>0.155577</td>\n",
       "      <td>0.946628</td>\n",
       "      <td>0.842188</td>\n",
       "      <td>0.821169</td>\n",
       "      <td>0.705123</td>\n",
       "      <td>0.979253</td>\n",
       "      <td>0.758515</td>\n",
       "      <td>00:26</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>30</td>\n",
       "      <td>0.110624</td>\n",
       "      <td>0.151422</td>\n",
       "      <td>0.946628</td>\n",
       "      <td>0.842786</td>\n",
       "      <td>0.820340</td>\n",
       "      <td>0.706501</td>\n",
       "      <td>0.979070</td>\n",
       "      <td>0.758878</td>\n",
       "      <td>00:26</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>31</td>\n",
       "      <td>0.107328</td>\n",
       "      <td>0.159087</td>\n",
       "      <td>0.948730</td>\n",
       "      <td>0.847534</td>\n",
       "      <td>0.831474</td>\n",
       "      <td>0.714712</td>\n",
       "      <td>0.980355</td>\n",
       "      <td>0.768475</td>\n",
       "      <td>00:26</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>32</td>\n",
       "      <td>0.101848</td>\n",
       "      <td>0.160788</td>\n",
       "      <td>0.944202</td>\n",
       "      <td>0.833787</td>\n",
       "      <td>0.813542</td>\n",
       "      <td>0.688872</td>\n",
       "      <td>0.978703</td>\n",
       "      <td>0.745570</td>\n",
       "      <td>00:26</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>\n",
       "\n",
       "    <div>\n",
       "      <progress value='5' class='' max='85' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      5.88% [5/85 00:01<00:24 0.1013]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "def save_callback(study, trial):\n",
    "    if study.best_trial == trial:\n",
    "        PATH = Path('./models/inception_multilabel_big.pkl')\n",
    "        PATH.parent.mkdir(parents=True, exist_ok=True)\n",
    "        global learn\n",
    "        learn.export(PATH)\n",
    "def objective(trial:optuna.Trial):    \n",
    "    # Define search space here. More info here https://optuna.readthedocs.io/en/stable/tutorial/10_key_features/002_configurations.html\n",
    "#     \n",
    "    tfms = []\n",
    "    random_shift = trial.suggest_float('rand_shift', 0.0, 0.5, step=.05) \n",
    "    noise = trial.suggest_float(\"noise\", 0.0, 1.5, step=.1) \n",
    "    window_slice = trial.suggest_float(\"window_slice\", 0.0, 0.6, step=.05) \n",
    "    rescale = trial.suggest_float(\"scale\", 0.2, 0.8, step=.1) \n",
    "    norm = trial.suggest_categorical('normalize', [0, 1]) \n",
    "    learning_rate = trial.suggest_float(\"learning_rate\", 1e-3, 1e-1, log=True) \n",
    "    depth = trial.suggest_int('depth', 8,11,step=1) #\n",
    "    conv_dropout = trial.suggest_float(\"conv_dropout\", 0.0, 0.05, step=.025) \n",
    "    fc_dropout = trial.suggest_float(\"fc_dropout\", 0.0, 0.05, step=.025) \n",
    "    nf = trial.suggest_int('num_filters', 16, 32, step=4) \n",
    "    \n",
    "    Xtfms = [TSRandomShift(magnitude=random_shift),TSMagMulNoise(noise),TSWindowSlicing(magnitude=window_slice),custom_tfms.Resample(scale_factor=rescale)]\n",
    "    if norm!=0:\n",
    "        Xtfms.append(custom_tfms.Normalize())\n",
    "    \n",
    "    batch_tfms = TSStandardize(by_sample=True)\n",
    "    tfms  = [None, TSMultiLabelClassification()]\n",
    "    batch_tfms = [TSStandardize(by_sample=True)]\n",
    "    dsets = TSDatasets(X.astype(float), y_multi, tfms=tfms, splits=splits) # inplace=True by default\n",
    "    dls   = TSDataLoaders.from_dsets(dsets.train,dsets.valid, bs=[64, 128], batch_tfms=batch_tfms, num_workers=0)\n",
    "    metrics =[accuracy_multi, balanced_accuracy_multi, precision_multi, recall_multi, specificity_multi, F1_multi] \n",
    "\n",
    "    model = InceptionTimePlus(dls.vars, dls.c, dls.len, conv_dropout=conv_dropout, depth=depth,fc_dropout = fc_dropout,nf = nf)\n",
    "    global learn\n",
    "    learn = Learner(dls, model, metrics=metrics,loss_func=nn.BCEWithLogitsLoss(), cbs=FastAIPruningCallback(trial))\n",
    "\n",
    "\n",
    "#     with ContextManagers([learn.no_logging(), learn.no_bar()]): # [Optional] this prevents fastai from printing anything during training\n",
    "    learn.fit_one_cycle(100, lr_max=learning_rate)\n",
    "\n",
    "    # Return the objective value\n",
    "    return learn.recorder.values[-1][-1] # return the f1 value and try to maximize it\n",
    "\n",
    "study_name = \"inception_study3\" # Unique identifier of the study.\n",
    "storage_name = \"sqlite:///{}.db\".format(study_name)\n",
    "study = optuna.create_study(study_name=study_name, storage=storage_name,direction='maximize',load_if_exists=True,\n",
    "                            pruner=optuna.pruners.PatientPruner(optuna.pruners.MedianPruner(n_warmup_steps=25),patience=20),sampler=optuna.samplers.RandomSampler())\n",
    "\n",
    "study.optimize(objective, n_trials=100,callbacks=[save_callback])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "dcd5bb71",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\u001b[0;31mInit signature:\u001b[0m\n",
       "\u001b[0mInceptionTimePlus\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0mc_in\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0mc_out\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0mseq_len\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0mnf\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m32\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0mnb_filters\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0mflatten\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0mconcat_pool\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0mfc_dropout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.0\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0mbn\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0my_range\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0mcustom_head\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0mks\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m40\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0mbottleneck\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0mpadding\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'same'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0mcoord\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0mseparable\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0mdilation\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0mstride\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0mconv_dropout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.0\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0msa\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0mse\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0mnorm\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'Batch'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0mzero_norm\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0mbn_1st\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0mact\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m<\u001b[0m\u001b[0;32mclass\u001b[0m \u001b[0;34m'torch.nn.modules.activation.ReLU'\u001b[0m\u001b[0;34m>\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0mact_kwargs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
       "\u001b[0;31mDocstring:\u001b[0m     \n",
       "A sequential container.\n",
       "Modules will be added to it in the order they are passed in the\n",
       "constructor. Alternatively, an ``OrderedDict`` of modules can be\n",
       "passed in. The ``forward()`` method of ``Sequential`` accepts any\n",
       "input and forwards it to the first module it contains. It then\n",
       "\"chains\" outputs to inputs sequentially for each subsequent module,\n",
       "finally returning the output of the last module.\n",
       "\n",
       "The value a ``Sequential`` provides over manually calling a sequence\n",
       "of modules is that it allows treating the whole container as a\n",
       "single module, such that performing a transformation on the\n",
       "``Sequential`` applies to each of the modules it stores (which are\n",
       "each a registered submodule of the ``Sequential``).\n",
       "\n",
       "What's the difference between a ``Sequential`` and a\n",
       ":class:`torch.nn.ModuleList`? A ``ModuleList`` is exactly what it\n",
       "sounds like--a list for storing ``Module`` s! On the other hand,\n",
       "the layers in a ``Sequential`` are connected in a cascading way.\n",
       "\n",
       "Example::\n",
       "\n",
       "    # Using Sequential to create a small model. When `model` is run,\n",
       "    # input will first be passed to `Conv2d(1,20,5)`. The output of\n",
       "    # `Conv2d(1,20,5)` will be used as the input to the first\n",
       "    # `ReLU`; the output of the first `ReLU` will become the input\n",
       "    # for `Conv2d(20,64,5)`. Finally, the output of\n",
       "    # `Conv2d(20,64,5)` will be used as input to the second `ReLU`\n",
       "    model = nn.Sequential(\n",
       "              nn.Conv2d(1,20,5),\n",
       "              nn.ReLU(),\n",
       "              nn.Conv2d(20,64,5),\n",
       "              nn.ReLU()\n",
       "            )\n",
       "\n",
       "    # Using Sequential with OrderedDict. This is functionally the\n",
       "    # same as the above code\n",
       "    model = nn.Sequential(OrderedDict([\n",
       "              ('conv1', nn.Conv2d(1,20,5)),\n",
       "              ('relu1', nn.ReLU()),\n",
       "              ('conv2', nn.Conv2d(20,64,5)),\n",
       "              ('relu2', nn.ReLU())\n",
       "            ]))\n",
       "\u001b[0;31mInit docstring:\u001b[0m Initializes internal Module state, shared by both nn.Module and ScriptModule.\n",
       "\u001b[0;31mFile:\u001b[0m           ~/miniconda3/envs/ddsp/lib/python3.8/site-packages/tsai/models/InceptionTimePlus.py\n",
       "\u001b[0;31mType:\u001b[0m           type\n",
       "\u001b[0;31mSubclasses:\u001b[0m     InCoordTime, XCoordTime\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "InceptionTimePlus?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63245b0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import transformation_funcs as custom_tfms\n",
    "tfms  = [[TSRandomShift(magnitude=0.2),TSMagMulNoise(),custom_tfms.TSNormalize(),TSWindowSlicing(magnitude=0.2)], TSMultiLabelClassification()]\n",
    "batch_tfms = [TSStandardize(by_sample=True)]\n",
    "dsets = TSDatasets(X.astype(float), y_multi, tfms=tfms, splits=splits) # inplace=True by default\n",
    "dls   = TSDataLoaders.from_dsets(dsets.train,dsets.valid, bs=[32, 128], batch_tfms=batch_tfms, num_workers=0)\n",
    "metrics =[ precision_multi, recall_multi, specificity_multi, F1_multi] \n",
    "model = InceptionTimePlus(dls.vars, dls.c, dls.len, depth=13,)\n",
    "# learn = Learner(dls, model, metrics=metrics, cbs=ShowGraph())\n",
    "learn.fit_one_cycle(200, lr_max=0.004178080960048705)\n",
    "learn.recorder.plot_metrics()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "0caeb06a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                              precision    recall  f1-score   support\n",
      "\n",
      "   right bundle branch block       0.54      0.92      0.68        79\n",
      "        ventricular ectopics       0.89      0.94      0.91       127\n",
      "         atrial fibrillation       1.00      0.81      0.89        21\n",
      "    left bundle branch block       0.44      0.38      0.41        65\n",
      "                st elevation       0.90      0.93      0.92       159\n",
      "         1st degree av block       0.64      0.72      0.67        78\n",
      "premature atrial contraction       0.82      0.52      0.64        79\n",
      "                sinus rhythm       0.80      0.36      0.50        22\n",
      "               st depression       0.91      0.51      0.65        57\n",
      "\n",
      "                    accuracy                           0.75       687\n",
      "                   macro avg       0.77      0.68      0.70       687\n",
      "                weighted avg       0.77      0.75      0.75       687\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "tfms  = [None, TSMultiLabelClassification()]\n",
    "batch_tfms = [TSStandardize(by_sample=True)]\n",
    "dsets = TSDatasets(X.astype(float), y_multi, tfms=tfms, splits=(splits[0],splits[2])) # inplace=True by default\n",
    "dls   = TSDataLoaders.from_dsets(dsets.train,dsets.valid, bs=[64, 128], batch_tfms=batch_tfms, num_workers=0)\n",
    "valid_probas, valid_targets, valid_preds = learn.get_preds(dl=dls.valid, with_decoded=True)\n",
    "\n",
    "y_pred=np.argmax(valid_preds, axis=1)\n",
    "y_test=np.argmax(valid_targets, axis=1)\n",
    "\n",
    "print(classification_report(y_test, y_pred,target_names = df.columns))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
