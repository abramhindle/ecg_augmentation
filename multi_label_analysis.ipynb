{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "impaired-speaking",
   "metadata": {},
   "outputs": [],
   "source": [
    "from helper_code import *\n",
    "import numpy as np, os, sys, joblib\n",
    "import ecg_plot\n",
    "import pandas as pd\n",
    "from glob import glob\n",
    "import os\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tsai.all import *\n",
    "import torch\n",
    "import optuna\n",
    "from optuna.integration import FastAIPruningCallback\n",
    "\n",
    "torch.cuda.set_device(1) \n",
    "\n",
    "\n",
    "def snomedConvert(code,snomed=True):\n",
    "    codes =  pd.read_csv(\"data/codes.csv\",sep=\";\")[[\"Dx\",\"SNOMED CT Code\"]]\n",
    "    if snomed:\n",
    "        df.columns = [codes[codes[\"SNOMED CT Code\"] == int(x)].iloc[0][\"Dx\"] for x in df.columns]\n",
    "        return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "informal-syndication",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv(\"data/WFDB_CPSC2018.csv\")\n",
    "codes =  pd.read_csv(\"data/codes.csv\",sep=\";\")\n",
    "# df.columns = [codes[codes[\"SNOMED CT Code\"] == x].iloc[0][\"Dx\"] for x in df.columns]\n",
    "np.sum(codes[\"SNOMED CT Code\"] == int(df.columns[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "amber-momentum",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ True, False, False, ..., False, False, False])"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X = np.load('./data/big_numpy_datasets/WFDB_CPSC2018.npy', mmap_mode='c')\n",
    "df = pd.read_csv(\"data/WFDB_CPSC2018.csv\").drop(columns=[\"headers\",\"leads\"])\n",
    "\n",
    "y = snomedConvert(df)\n",
    "y = y[y.columns[0]].to_numpy()\n",
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "experienced-image",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1152x36 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "((#4815) [2849,6802,4096,496,2012,173,1178,5343,505,5739...],\n",
       " (#1375) [4964,5847,413,6628,1735,5258,6065,3308,3619,3857...],\n",
       " (#687) [2626,5678,5053,2717,3363,963,5856,5471,1253,148...])"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "splits = get_splits(y, valid_size=.2,test_size=0.1, stratify=True, random_state=23, shuffle=True)\n",
    "splits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "ranging-redhead",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Counts by label: {'right bundle branch block': 1857, 'sinus rhythm': 918, 'atrial fibrillation': 1221, 'ventricular ectopics': 700, 'st depression': 869, 'left bundle branch block': 236, 'st elevation': 220, '1st degree av block': 722, 'premature atrial contraction': 616}\n"
     ]
    }
   ],
   "source": [
    "df = pd.read_csv(\"data/WFDB_CPSC2018.csv\").drop(columns=[\"headers\",\"leads\"])\n",
    "y = snomedConvert(df)\n",
    "y_multi = []\n",
    "for i,row in y.iterrows():\n",
    "    sample_labels = []\n",
    "    for i,r in enumerate(row):\n",
    "        if r == True:\n",
    "            sample_labels.append(y.columns[i])\n",
    "        \n",
    "    y_multi.append(list(tuple(sample_labels)))\n",
    "label_counts = collections.Counter([a for r in y_multi for a in r])\n",
    "print('Counts by label:', dict(label_counts))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "da1b39d0-8287-426e-ba5d-73adeddb68c4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\u001b[0;31mInit signature:\u001b[0m\n",
       "\u001b[0mMiniRocketPlus\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0mc_in\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0mc_out\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0mseq_len\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0mnum_features\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m10000\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0mmax_dilations_per_kernel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m32\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0mkernel_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m9\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0mmax_num_channels\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0mmax_num_kernels\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m84\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0mbn\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0mfc_dropout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0madd_lsaz\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
       "\u001b[0;31mDocstring:\u001b[0m     \n",
       "A sequential container.\n",
       "Modules will be added to it in the order they are passed in the\n",
       "constructor. Alternatively, an ``OrderedDict`` of modules can be\n",
       "passed in. The ``forward()`` method of ``Sequential`` accepts any\n",
       "input and forwards it to the first module it contains. It then\n",
       "\"chains\" outputs to inputs sequentially for each subsequent module,\n",
       "finally returning the output of the last module.\n",
       "\n",
       "The value a ``Sequential`` provides over manually calling a sequence\n",
       "of modules is that it allows treating the whole container as a\n",
       "single module, such that performing a transformation on the\n",
       "``Sequential`` applies to each of the modules it stores (which are\n",
       "each a registered submodule of the ``Sequential``).\n",
       "\n",
       "What's the difference between a ``Sequential`` and a\n",
       ":class:`torch.nn.ModuleList`? A ``ModuleList`` is exactly what it\n",
       "sounds like--a list for storing ``Module`` s! On the other hand,\n",
       "the layers in a ``Sequential`` are connected in a cascading way.\n",
       "\n",
       "Example::\n",
       "\n",
       "    # Using Sequential to create a small model. When `model` is run,\n",
       "    # input will first be passed to `Conv2d(1,20,5)`. The output of\n",
       "    # `Conv2d(1,20,5)` will be used as the input to the first\n",
       "    # `ReLU`; the output of the first `ReLU` will become the input\n",
       "    # for `Conv2d(20,64,5)`. Finally, the output of\n",
       "    # `Conv2d(20,64,5)` will be used as input to the second `ReLU`\n",
       "    model = nn.Sequential(\n",
       "              nn.Conv2d(1,20,5),\n",
       "              nn.ReLU(),\n",
       "              nn.Conv2d(20,64,5),\n",
       "              nn.ReLU()\n",
       "            )\n",
       "\n",
       "    # Using Sequential with OrderedDict. This is functionally the\n",
       "    # same as the above code\n",
       "    model = nn.Sequential(OrderedDict([\n",
       "              ('conv1', nn.Conv2d(1,20,5)),\n",
       "              ('relu1', nn.ReLU()),\n",
       "              ('conv2', nn.Conv2d(20,64,5)),\n",
       "              ('relu2', nn.ReLU())\n",
       "            ]))\n",
       "\u001b[0;31mInit docstring:\u001b[0m Initializes internal Module state, shared by both nn.Module and ScriptModule.\n",
       "\u001b[0;31mFile:\u001b[0m           ~/miniconda3/envs/ddsp/lib/python3.8/site-packages/tsai/models/MINIROCKETPlus_Pytorch.py\n",
       "\u001b[0;31mType:\u001b[0m           type\n",
       "\u001b[0;31mSubclasses:\u001b[0m     \n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "MiniRocketPlus?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "demanding-viewer",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "def objective(trial:optuna.Trial):\n",
    "    \n",
    "    # Define search space here. More info here https://optuna.readthedocs.io/en/stable/tutorial/10_key_features/002_configurations.html\n",
    "    max_length = trial.suggest_categorical('max_length',[25,50,100,250,500,700]) # search through all integer values between 3 and 9 with 3 increment steps\n",
    "    dropout_t = trial.suggest_float(\"dropout_rate\", 0.0, 0.5, step=.1) # search through all float values between 0.0 and 0.5 with 0.1 increment steps\n",
    "    dropout_fc = trial.suggest_float(\"dropout_rate\", 0.0, 0.9, step=.1) # search through all float values between 0.0 and 0.5 with 0.1 increment steps\n",
    "    learning_rate = trial.suggest_float(\"learning_rate\", 1e-5, 1e-2, log=True)  # search through all float values between 0.0 and 0.5 in log increment steps\n",
    "    \n",
    "    batch_tfms = TSStandardize(by_sample=True)\n",
    "    tfms  = [None, TSMultiLabelClassification()]\n",
    "    batch_tfms = [TSStandardize(by_sample=True)]\n",
    "    dsets = TSDatasets(X.astype(float), y_multi, tfms=tfms, splits=splits) # inplace=True by default\n",
    "    dls   = TSDataLoaders.from_dsets(dsets.train,dsets.valid, bs=[64, 128], batch_tfms=batch_tfms, num_workers=0)\n",
    "    metrics =[accuracy_multi, balanced_accuracy_multi, precision_multi, recall_multi, specificity_multi, F1_multi] \n",
    "\n",
    "    model = MiniRocketPlus(dls.vars, dls.c, dls.len, max_seq_len=max_length, dropout=dropout_t, fc_dropout=dropout_fc)\n",
    "    learn = Learner(dls, model, metrics=metrics,loss_func=nn.BCEWithLogitsLoss(), cbs=FastAIPruningCallback(trial))\n",
    "\n",
    "\n",
    "#     with ContextManagers([learn.no_logging(), learn.no_bar()]): # [Optional] this prevents fastai from printing anything during training\n",
    "    learn.fit_one_cycle(200, lr_max=learning_rate)\n",
    "\n",
    "    # Return the objective value\n",
    "    return learn.recorder.values[-1][-1] # return the f1 value and try to maximize it\n",
    "\n",
    "study_name = \"transformer\" # Unique identifier of the study.\n",
    "storage_name = \"sqlite:///{}.db\".format(study_name)\n",
    "study = optuna.create_study(study_name=study_name, storage=storage_name,direction='maximize')\n",
    "\n",
    "study.optimize(objective, n_trials=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "desperate-covering",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "<style>\n",
       "    /* Turns off some styling */\n",
       "    progress {\n",
       "        /* gets rid of default border in Firefox and Opera. */\n",
       "        border: none;\n",
       "        /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
       "        background-size: auto;\n",
       "    }\n",
       "    .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n",
       "        background: #F44336;\n",
       "    }\n",
       "</style>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      <progress value='0' class='' max='200' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      0.00% [0/200 00:00<00:00]\n",
       "    </div>\n",
       "    \n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>epoch</th>\n",
       "      <th>train_loss</th>\n",
       "      <th>valid_loss</th>\n",
       "      <th>accuracy_multi</th>\n",
       "      <th>balanced_accuracy_multi</th>\n",
       "      <th>precision_multi</th>\n",
       "      <th>recall_multi</th>\n",
       "      <th>specificity_multi</th>\n",
       "      <th>F1_multi</th>\n",
       "      <th>time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>\n",
       "\n",
       "    <div>\n",
       "      <progress value='0' class='' max='75' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      0.00% [0/75 00:00<00:00]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "TypeError",
     "evalue": "no implementation found for 'torch.nn.functional.binary_cross_entropy_with_logits' on types that implement __torch_function__: [<class 'tsai.data.core.TSTensor'>, <class 'fastai.torch_core.TensorMultiCategory'>]",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Input \u001b[0;32mIn [69]\u001b[0m, in \u001b[0;36m<cell line: 9>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[38;5;66;03m# model = TST(dls.vars, dls.c, dls.len,max_seq_len=25,dropout=.2,fc_dropout=0.7)\u001b[39;00m\n\u001b[1;32m      8\u001b[0m learn \u001b[38;5;241m=\u001b[39m Learner(dls, model, metrics\u001b[38;5;241m=\u001b[39mmetrics,loss_func\u001b[38;5;241m=\u001b[39mnn\u001b[38;5;241m.\u001b[39mBCEWithLogitsLoss(), cbs\u001b[38;5;241m=\u001b[39mShowGraph())\n\u001b[0;32m----> 9\u001b[0m \u001b[43mlearn\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit_one_cycle\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m200\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlr_max\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m1e-4\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m     10\u001b[0m learn\u001b[38;5;241m.\u001b[39mrecorder\u001b[38;5;241m.\u001b[39mplot_metrics()\n",
      "File \u001b[0;32m~/miniconda3/envs/ddsp/lib/python3.8/site-packages/fastai/callback/schedule.py:116\u001b[0m, in \u001b[0;36mfit_one_cycle\u001b[0;34m(self, n_epoch, lr_max, div, div_final, pct_start, wd, moms, cbs, reset_opt)\u001b[0m\n\u001b[1;32m    113\u001b[0m lr_max \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39marray([h[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mlr\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;28;01mfor\u001b[39;00m h \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mopt\u001b[38;5;241m.\u001b[39mhypers])\n\u001b[1;32m    114\u001b[0m scheds \u001b[38;5;241m=\u001b[39m {\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mlr\u001b[39m\u001b[38;5;124m'\u001b[39m: combined_cos(pct_start, lr_max\u001b[38;5;241m/\u001b[39mdiv, lr_max, lr_max\u001b[38;5;241m/\u001b[39mdiv_final),\n\u001b[1;32m    115\u001b[0m           \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmom\u001b[39m\u001b[38;5;124m'\u001b[39m: combined_cos(pct_start, \u001b[38;5;241m*\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmoms \u001b[38;5;28;01mif\u001b[39;00m moms \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m moms))}\n\u001b[0;32m--> 116\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mn_epoch\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcbs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mParamScheduler\u001b[49m\u001b[43m(\u001b[49m\u001b[43mscheds\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[43mL\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcbs\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mreset_opt\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mreset_opt\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mwd\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mwd\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/ddsp/lib/python3.8/site-packages/fastai/learner.py:221\u001b[0m, in \u001b[0;36mLearner.fit\u001b[0;34m(self, n_epoch, lr, wd, cbs, reset_opt)\u001b[0m\n\u001b[1;32m    219\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mopt\u001b[38;5;241m.\u001b[39mset_hypers(lr\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlr \u001b[38;5;28;01mif\u001b[39;00m lr \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m lr)\n\u001b[1;32m    220\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_epoch \u001b[38;5;241m=\u001b[39m n_epoch\n\u001b[0;32m--> 221\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_with_events\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_do_fit\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mfit\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mCancelFitException\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_end_cleanup\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/ddsp/lib/python3.8/site-packages/fastai/learner.py:163\u001b[0m, in \u001b[0;36mLearner._with_events\u001b[0;34m(self, f, event_type, ex, final)\u001b[0m\n\u001b[1;32m    162\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_with_events\u001b[39m(\u001b[38;5;28mself\u001b[39m, f, event_type, ex, final\u001b[38;5;241m=\u001b[39mnoop):\n\u001b[0;32m--> 163\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m: \u001b[38;5;28mself\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mbefore_\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mevent_type\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m);  \u001b[43mf\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    164\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m ex: \u001b[38;5;28mself\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mafter_cancel_\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mevent_type\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m    165\u001b[0m     \u001b[38;5;28mself\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mafter_\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mevent_type\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m);  final()\n",
      "File \u001b[0;32m~/miniconda3/envs/ddsp/lib/python3.8/site-packages/fastai/learner.py:212\u001b[0m, in \u001b[0;36mLearner._do_fit\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    210\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m epoch \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_epoch):\n\u001b[1;32m    211\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mepoch\u001b[38;5;241m=\u001b[39mepoch\n\u001b[0;32m--> 212\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_with_events\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_do_epoch\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mepoch\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mCancelEpochException\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/ddsp/lib/python3.8/site-packages/fastai/learner.py:163\u001b[0m, in \u001b[0;36mLearner._with_events\u001b[0;34m(self, f, event_type, ex, final)\u001b[0m\n\u001b[1;32m    162\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_with_events\u001b[39m(\u001b[38;5;28mself\u001b[39m, f, event_type, ex, final\u001b[38;5;241m=\u001b[39mnoop):\n\u001b[0;32m--> 163\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m: \u001b[38;5;28mself\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mbefore_\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mevent_type\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m);  \u001b[43mf\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    164\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m ex: \u001b[38;5;28mself\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mafter_cancel_\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mevent_type\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m    165\u001b[0m     \u001b[38;5;28mself\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mafter_\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mevent_type\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m);  final()\n",
      "File \u001b[0;32m~/miniconda3/envs/ddsp/lib/python3.8/site-packages/fastai/learner.py:206\u001b[0m, in \u001b[0;36mLearner._do_epoch\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    205\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_do_epoch\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[0;32m--> 206\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_do_epoch_train\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    207\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_do_epoch_validate()\n",
      "File \u001b[0;32m~/miniconda3/envs/ddsp/lib/python3.8/site-packages/fastai/learner.py:198\u001b[0m, in \u001b[0;36mLearner._do_epoch_train\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    196\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_do_epoch_train\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m    197\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdl \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdls\u001b[38;5;241m.\u001b[39mtrain\n\u001b[0;32m--> 198\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_with_events\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mall_batches\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mtrain\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mCancelTrainException\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/ddsp/lib/python3.8/site-packages/fastai/learner.py:163\u001b[0m, in \u001b[0;36mLearner._with_events\u001b[0;34m(self, f, event_type, ex, final)\u001b[0m\n\u001b[1;32m    162\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_with_events\u001b[39m(\u001b[38;5;28mself\u001b[39m, f, event_type, ex, final\u001b[38;5;241m=\u001b[39mnoop):\n\u001b[0;32m--> 163\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m: \u001b[38;5;28mself\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mbefore_\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mevent_type\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m);  \u001b[43mf\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    164\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m ex: \u001b[38;5;28mself\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mafter_cancel_\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mevent_type\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m    165\u001b[0m     \u001b[38;5;28mself\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mafter_\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mevent_type\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m);  final()\n",
      "File \u001b[0;32m~/miniconda3/envs/ddsp/lib/python3.8/site-packages/fastai/learner.py:169\u001b[0m, in \u001b[0;36mLearner.all_batches\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    167\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mall_batches\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m    168\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_iter \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlen\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdl)\n\u001b[0;32m--> 169\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m o \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdl): \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mone_batch\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mo\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/ddsp/lib/python3.8/site-packages/tsai/learner.py:38\u001b[0m, in \u001b[0;36mone_batch\u001b[0;34m(self, i, b)\u001b[0m\n\u001b[1;32m     36\u001b[0m b_on_device \u001b[38;5;241m=\u001b[39m to_device(b, device\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdls\u001b[38;5;241m.\u001b[39mdevice) \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdls\u001b[38;5;241m.\u001b[39mdevice \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m b\n\u001b[1;32m     37\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_split(b_on_device)\n\u001b[0;32m---> 38\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_with_events\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_do_one_batch\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mbatch\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mCancelBatchException\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/ddsp/lib/python3.8/site-packages/fastai/learner.py:163\u001b[0m, in \u001b[0;36mLearner._with_events\u001b[0;34m(self, f, event_type, ex, final)\u001b[0m\n\u001b[1;32m    162\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_with_events\u001b[39m(\u001b[38;5;28mself\u001b[39m, f, event_type, ex, final\u001b[38;5;241m=\u001b[39mnoop):\n\u001b[0;32m--> 163\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m: \u001b[38;5;28mself\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mbefore_\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mevent_type\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m);  \u001b[43mf\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    164\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m ex: \u001b[38;5;28mself\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mafter_cancel_\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mevent_type\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m    165\u001b[0m     \u001b[38;5;28mself\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mafter_\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mevent_type\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m);  final()\n",
      "File \u001b[0;32m~/miniconda3/envs/ddsp/lib/python3.8/site-packages/fastai/learner.py:175\u001b[0m, in \u001b[0;36mLearner._do_one_batch\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    173\u001b[0m \u001b[38;5;28mself\u001b[39m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mafter_pred\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m    174\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39myb):\n\u001b[0;32m--> 175\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mloss_grad \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mloss_func\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpred\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43myb\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    176\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mloss \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mloss_grad\u001b[38;5;241m.\u001b[39mclone()\n\u001b[1;32m    177\u001b[0m \u001b[38;5;28mself\u001b[39m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mafter_loss\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "File \u001b[0;32m~/miniconda3/envs/ddsp/lib/python3.8/site-packages/torch/nn/modules/module.py:1102\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1098\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1099\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1100\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1101\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1102\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1103\u001b[0m \u001b[38;5;66;03m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1104\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[38;5;241m=\u001b[39m [], []\n",
      "File \u001b[0;32m~/miniconda3/envs/ddsp/lib/python3.8/site-packages/torch/nn/modules/loss.py:704\u001b[0m, in \u001b[0;36mBCEWithLogitsLoss.forward\u001b[0;34m(self, input, target)\u001b[0m\n\u001b[1;32m    703\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m: Tensor, target: Tensor) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tensor:\n\u001b[0;32m--> 704\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mF\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbinary_cross_entropy_with_logits\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtarget\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    705\u001b[0m \u001b[43m                                              \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mweight\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    706\u001b[0m \u001b[43m                                              \u001b[49m\u001b[43mpos_weight\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpos_weight\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    707\u001b[0m \u001b[43m                                              \u001b[49m\u001b[43mreduction\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mreduction\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/ddsp/lib/python3.8/site-packages/torch/nn/functional.py:2963\u001b[0m, in \u001b[0;36mbinary_cross_entropy_with_logits\u001b[0;34m(input, target, weight, size_average, reduce, reduction, pos_weight)\u001b[0m\n\u001b[1;32m   2927\u001b[0m \u001b[38;5;124mr\u001b[39m\u001b[38;5;124;03m\"\"\"Function that measures Binary Cross Entropy between target and input\u001b[39;00m\n\u001b[1;32m   2928\u001b[0m \u001b[38;5;124;03mlogits.\u001b[39;00m\n\u001b[1;32m   2929\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   2960\u001b[0m \u001b[38;5;124;03m     >>> loss.backward()\u001b[39;00m\n\u001b[1;32m   2961\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m   2962\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m has_torch_function_variadic(\u001b[38;5;28minput\u001b[39m, target, weight, pos_weight):\n\u001b[0;32m-> 2963\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mhandle_torch_function\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   2964\u001b[0m \u001b[43m        \u001b[49m\u001b[43mbinary_cross_entropy_with_logits\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2965\u001b[0m \u001b[43m        \u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtarget\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mweight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpos_weight\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2966\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2967\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtarget\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2968\u001b[0m \u001b[43m        \u001b[49m\u001b[43mweight\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mweight\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2969\u001b[0m \u001b[43m        \u001b[49m\u001b[43msize_average\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msize_average\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2970\u001b[0m \u001b[43m        \u001b[49m\u001b[43mreduce\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mreduce\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2971\u001b[0m \u001b[43m        \u001b[49m\u001b[43mreduction\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mreduction\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2972\u001b[0m \u001b[43m        \u001b[49m\u001b[43mpos_weight\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpos_weight\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2973\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   2974\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m size_average \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mor\u001b[39;00m reduce \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m   2975\u001b[0m     reduction_enum \u001b[38;5;241m=\u001b[39m _Reduction\u001b[38;5;241m.\u001b[39mlegacy_get_enum(size_average, reduce)\n",
      "File \u001b[0;32m~/miniconda3/envs/ddsp/lib/python3.8/site-packages/torch/overrides.py:1361\u001b[0m, in \u001b[0;36mhandle_torch_function\u001b[0;34m(public_api, relevant_args, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1358\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m result\n\u001b[1;32m   1360\u001b[0m func_name \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m.\u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;241m.\u001b[39mformat(public_api\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__module__\u001b[39m, public_api\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m)\n\u001b[0;32m-> 1361\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mno implementation found for \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m on types that implement \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   1362\u001b[0m                 \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m__torch_function__: \u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m   1363\u001b[0m                 \u001b[38;5;241m.\u001b[39mformat(func_name, [\u001b[38;5;28mtype\u001b[39m(arg) \u001b[38;5;28;01mfor\u001b[39;00m arg \u001b[38;5;129;01min\u001b[39;00m overloaded_args]))\n",
      "\u001b[0;31mTypeError\u001b[0m: no implementation found for 'torch.nn.functional.binary_cross_entropy_with_logits' on types that implement __torch_function__: [<class 'tsai.data.core.TSTensor'>, <class 'fastai.torch_core.TensorMultiCategory'>]"
     ]
    }
   ],
   "source": [
    "tfms  = [None, TSMultiLabelClassification()]\n",
    "batch_tfms = [TSStandardize(by_sample=True)]\n",
    "dsets = TSDatasets(X.astype(float), y_multi, tfms=tfms, splits=splits) # inplace=True by default\n",
    "dls   = TSDataLoaders.from_dsets(dsets.train,dsets.valid, bs=[64, 128], batch_tfms=batch_tfms, num_workers=0)\n",
    "metrics =[accuracy_multi, balanced_accuracy_multi, precision_multi, recall_multi, specificity_multi, F1_multi] \n",
    "# model = MiniRocketPlus(dls.vars, dls.c,2500)\n",
    "# model = TST(dls.vars, dls.c, dls.len,max_seq_len=25,dropout=.2,fc_dropout=0.7)\n",
    "learn = Learner(dls, model, metrics=metrics,loss_func=nn.BCEWithLogitsLoss(), cbs=ShowGraph())\n",
    "learn.fit_one_cycle(200, lr_max=1e-4)\n",
    "learn.recorder.plot_metrics()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
